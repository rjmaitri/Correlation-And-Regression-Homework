---
output: 
  html_document: 
    df_print: kable
    theme: cerulean
---
  
<div align="center">
 <marquee behavior="alternate" bgcolor="#bb3434" direction="left" height:="" 
 loop="7" scrollamount="1" scrolldelay="2" width="100%">
 <span style="font-size: 20px;color:#FFFFFF">
 Correlation and Regression!</span></marquee>
</div>

---
title: "Homework 5"
author: "Bob Bartolini"
date: "10//2020"
output: html_document
  

---

https://github.com/rjmaitri/Correlation-And-Regression-Homework.git

```{r setup, include=FALSE}
#scrolling code output
knitr::opts_chunk$set(
	echo = TRUE,
	message = FALSE,
	warning = FALSE
)
options(width = 60)
local({
  hook_output <- knitr::knit_hooks$get('output')
  knitr::knit_hooks$set(output = function(x, options) {
    if (!is.null(options$max.height)) options$attr.output <- c(
      options$attr.output,
      sprintf('style="max-height: %s;"', options$max.height)
    )
    hook_output(x, options)
  })
})
```

```{r}
library(readr)
library(reactable)
library(broom)
library(dplyr)
library(tidyr)
library(ggplot2)


```

Note: Datasets are available at http://whitlockschluter.zoology.ubc.ca/data so you don’t have to type anything in (and have to load it!)

#### 1. Correlation - W&S Chapter 16
Data at https://whitlockschluter.zoology.ubc.ca/wp-content/data/chapter16/chap16q15LanguageGreyMatter.csv 

#### 1. Does learning a second language change brain structure? Mechelli tested 22 native Italian speakers who had learned English as a second language. Procifiencies in reading, writing, and speech were assesed using a number of tests whose results were summarized by a proficiency score. Gray-matter density was measured in the left inferior parietal region of the brain using a neuroimaging technique, as mm3 of gray matter per voxel. (A voxel is a picture element, or "pixel", in three dimensions.) The data are listed in the accompanying table. 


```{r}
#load the data (social coding note: I learned how to load directly from the web (last file in this HW is read.csv("web-link") but this code chunk works so I didn't fix it)
grey_proficiency <- read.csv("./data/chap16q15LanguageGreyMatter.csv")
#check the structure of the data
str(grey_proficiency)

```

```{r}


skimr::skim(grey_proficiency)


```

#### 1a. Display the association between the two variables in a scatter plot

```{r}

#plot grey matter by proficiency
ggplot(data = grey_proficiency,
       mapping = aes(x = proficiency, y = greymatter)) +
  geom_point()+
  stat_smooth(method =lm)+
  theme_bw()

```

<span style="color: green;"> The greymatter density increases with second language proficiency. </span>

#### 1b. Calculate the correlation between second language procifiency and grey-matter density

```{r}
#output the correlation matrix of this data
cor(grey_proficiency)

```

<span style="color: green;"> This correlation plot depicts the degree of association between grey-matter density and second language proficiency. We see that the covariance is 0.81.</span>

#### 1c. Test the Null Hypothesis of zero correlation.

```{r}
#fit the density-grey matter model
density_lm <- lm(greymatter ~ proficiency, data = grey_proficiency)

#extract the f_stat and P-value:
anova(density_lm) %>%
  tidy()

```

<span style="color: green;">We fail to accept the null hypothesis of zero correlation, as the p-value is 3.264e-06, which is less than our alpha of 0.05</span>



#### 2. Correlation - W&S Chapter 16
Data at https://whitlockschluter.zoology.ubc.ca/wp-content/data/chapter16/chap16q19LiverPreparation.csv

#### The following data are from a laboratory experiment by Smallwood et al. (1998) in which liver preparations from five rats were used to measure the relationship between the administered concentration of taurocholate (a salt normally occuring in liver bile) and the unbound fraction of taurocholate in the liver.

#### 2a. Calculate the correlation between the taurocholate unbound fraction and the concentration.

```{r}
#load the data
liver_data <- read.csv("data/chap16q19LiverPreparation.csv")
#check the structure
str(liver_data)



```

<span style="color: green;">This dataset displays the relationship between administered taurochlorate concentration and the fraction of unbound tuarocholorate in the liver.</span>




```{r}

skimr::skim(liver_data)

```

<span style="color: green;">The histograms don't show a normal distribution which infers transformation may be needed.</span>

```{r}
#correlation matrix for liver_data
cor(liver_data)


```

<span style="color: green;">The covariance of -0.85 indicates a strong negative correlation between the increasing concentration alongside a decreasing unbound fraction of taurocholate. The negative value indicates the direction of the effect concentration has on the unbound fraction.</span>

## 2b. Plot the relationship between the two variables in a graph.

```{r}

ggplot(data = liver_data,
       mapping = aes(x = concentration, y = unboundFraction)) +
  geom_point()+
  stat_smooth(method=lm)+
  theme_bw()


```


<span style="color: green;">Residuals have shrunk, log transformation has improved the fit of our model"</span>


## 2c. Examine the plot in part (b). The relationship appears to be maximally strong, yet the correlation coefficient you calculated in part (a) is not near the maximum possible value. 
Why not?

<span style="color: green;">The negative correlation coefficient approaches the minimum, since it has an increasing and decreasing variables. The correlation coefficient would approach the maximum if both variables were positive. </span>

## 2d. What steps would you take with these data to meet the assumptions of correlation analysis?

```{r}



#fit the unboundfraction_taurochlorate model
liver_lm <- lm(unboundFraction ~ concentration, data = liver_data)

summary(liver_lm)

```

<span style="color: green;">P-value is greater than 0.05, however, this may shrink with a bigger sample size.</span>

```{r}


coef(liver_lm)

```

```{r}


#use the fit model to test our data

#does the distribution of our predictions match our data?

unbound_sims <- simulate(liver_lm, nsim = 20) %>%
  pivot_longer(
    cols = everything(),
    names_to = "sim",
    values_to = "unboundFraction"
  )

#look if our predictions match the data
ggplot() +
  #layer the sims
  geom_density(data = unbound_sims, 
               mapping = aes(x = unboundFraction, group = sim), size =  0.2) +
  #layer the data 
   geom_density(data = liver_data, 
               mapping = aes(x = unboundFraction), size =  0.7, color = "red")

```

<span style="color: green;">Our simulations has some predictions which do not match our data. The small sample size appears to be an issue again. Also, the quantities appear to be in different scales.</span>



#is there a relationship between fitted and residual values

```{r}
#plot fitted vs. residual of the unbound fraction model
plot(liver_lm, which =1)

```

<span style="color: green;">The taurocholate data does not have a pattern for the residuals vs. fitted values, however, the small sample size does not give us any information for the scatter of the residual values. This plot would be more useful with replicate experiments.</span>



#### Did we satisfy normality and homoskedascity using a ggplot and levene test

```{r}

#Generate a QQplot
plot(liver_lm, which =2)

```

<span style="color: green;">The error generating process contains a normal distribution, as the residuals trend along a straight line</span>

#### Look for outliers with leverage. 

```{r}

#plot cooks distance to scan for outliers

plot(liver_lm, which =4)


```

<span style="color: green;">Rat #5 is an outlier, as it contains a Cook's distance over 1. </span>

```{r}
plot(liver_lm, which = 5)

```

<span style="color: green;">Rat samples 1 and 5 have a considerable amount of leverage</span>

<span style="color: green;">These tests of assumptions contain some minor failures, however replicate experiments should be conducted before reconstructing the model. If further data fails these tests, the taurocholate administration v. unbound fraction model may need to be revised based on these diagnostic tests of assumptions. More predictors, such as proteins relevant to unbound taurocholate may need to be investigated and incorporated to the model. </span>


#### 3. Correlation SE
#### Consider the following dataset:



cats	happiness_score
-0.30	-0.57
0.42	-0.10
0.85	-0.04
-0.45	-0.29
0.22	0.42
-0.12	-0.92
1.46	0.99
-0.79	-0.62
0.40	1.14
-0.07	0.33

```{r}

cats <- c(-0.30,0.42,0.85,-0.45,0.22,-0.12,1.46,-0.79,0.40,-0.07)

happiness_score <- c(-0.57,-0.10,-0.04,-0.29,0.42,-0.92,0.99,-0.62,1.14,0.33)

cats_happiness <- data.frame(cats, happiness_score)

```


#### 3a. Are these two variables correlated? What is the output of cor() here. What does a test show you?


```{r}
#ouput correlation matrix, created object for part 3c.
cat_cor <- cor(cats_happiness)

```


#### 3b. What is the SE of the correlation based on the info from cor.test()

```{r}

cor_test <- cor.test(cats_happiness$cats, cats_happiness$happiness_score)

```

<span style="color: green;">t = r/SE</span>

<span style="color: green;">r = 0.6758, t = 2.5938</span>

<span style="color: green;">2.5938 = 0.6758/SE</span>

<span style="color: green;">2.5938SE=0.6758</span>

<span style="color: green;">SE=0.6758/2.5938</span>

<span style="color: green;">SE=0.26</span>

<span style="color: green;">The standard error is *0.26*</span>


#### 3c. Now, what is the SE via simulation? To do this, you’ll need to use cor() and get the relevant parameter from the output (remember - you get a matrix back, so, what’s the right index!), replicate(), and sample() or dplyr::sample_n() with replace=TRUE to get, let’s say, 1000 correlations. How does this compare to your value above?

```{r}


cats <- replicate(1000, cor(sample_n(cats_happiness, size = nrow(cats_happiness), replace = TRUE))[1,2])


```

<span style="color: green;">The SE of 1000 simulated correlations is `r sd(cats)`</span>



#### 4. W&S Chapter 17
#### Data at https://whitlockschluter.zoology.ubc.ca/wp-content/data/chapter17/chap17q19GrasslandNutrientsPlantSpecies.csv
#### You might think that increasing the resources avaiable would elevate the number of plant species that an area could support, but the evidence suggests otherwise. The data in accompanying table are from Park Grass Experiment at Rothamsted Experimental Station in the U.K., where grassland field plots have been fertilized annually for the  past 150 years. The number of plant species recirded in 10 plots is given in response to the number of different nutrient types added in the fertilizer treatment (nutrient types include nitrogen, phosphorus, potassium and so on).

```{r}
plot <-  c(1,2,3,4,5,6,7,8,9,10)
Nutrients <-  c(0,0,0,1,2,3,1,3,4,4)
Species <- c(36,36,32,34,33,30,20,23,21,16)


plant_nutrient <- data.frame(plot, Nutrients, Species)



```

#### 4a. Draw the scatter plot of these data. Which variable should be the explanatory variable (X), and which should be the response variable (Y)?

<span style="color: green;">The number of plant species is the response variable (Y) and the explanatory variable is the number nutrients added (X)

```{r}
ggplot(data = plant_nutrient,
       mapping = aes(x = Nutrients, y = Species)) +
  geom_point(colour = "yellow", size =2)+
  theme_dark()

```

#### 4b. What was the rate of change in the number of plant species supported per nutrient type added? Provide a standard error in your estimate.

```{r}
#fit a linear model
Species_nutrients_mod <- lm(Species ~ Nutrients, data =plant_nutrient)
#find the slope of the line
print(Species_nutrients_mod)
```

<span style="color: green;">Species decrease by 3.339 for each nutrient added to a plot.</span>

```{r}

cor_plants <- cor.test(plant_nutrient$Nutrients, plant_nutrient$Species)


cor_plants

```


<span style="color: green;">Calculate standard error of the slope using the formula SE=slope/t gives `r -3.339/-3.0398` </span>

#### 4c. Add the least-squares regression to your scatter plot. What fraction of the variation in the number of plant species is "explained" by the number of nutrients added?

```{r}

ggplot(data = plant_nutrient,
       mapping = aes(x = Nutrients, y = Species)) +
  geom_point(colour = "yellow", size =2)+
  stat_smooth(method =lm, fill="pink", colour="green", size=1)+
  theme_dark()

```

<span style="color: green;">The fraction of variation in the number of species related to number of nutrients is r<sup>2</sup> = `r summary(Species_nutrients_mod)$r.squared`</span>

#### 4d. Test the null hypothesis, that no treatment effect on the number of plant species.

<span style="color: green;">We fail to accept the null hypothesis (p:value = `r cor_plants$p.value`) that there is no treatment effect on the number of plant species.</span>

5. W&S Chapter 17-25
https://whitlockschluter.zoology.ubc.ca/wp-content/data/chapter17/chap17q25BeetleWingsAndHorns.csv 

#### 5. Many species of beetle produce large horns that are used as weapons or shields. The resources require to build these horns, though, might be diverted from other useful structures. To test this, Emlen (2001) measured the sizes of wings and horns in 19 females of beetle species, Onthopagus Saggitarius. Both traits were scaled for body-size differences and hence are referred to as relative horn and wing sizes. Emlen's data are shown in the following scatter plot along with the least squares regression line (Y = -0.13 - 132.6X)

#### We used this regression line to predict horn lengths at each of the 19 observed horn sizes. These are given in the following table along with the raw data. 

```{r}
#load beetle data
beetle_df <- read.csv("data/chap17q25BeetleWingsAndHorns.csv")
#check the structure
str(beetle_df)


```

```{r}

skimr::skim(beetle_df)

```

```{r}
ggplot(data = beetle_df,
       mapping = aes(x = wingMass, y = hornSize)) +
  geom_point(colour = "yellow", size =2, shape = 1)+
  stat_smooth(method =lm, fill="pink", colour="blue", size=1)+
  theme_dark()


```

#### 4a. Use these results to calculate the residuals.

```{r}

beetle_lm <- lm(hornSize ~ wingMass, data = beetle_df)

hist(residuals(beetle_lm))

```

#### 4b. Use your resutls form part (a) to produce the residual plot.

```{r}
#But wait, theres more ####

library(modelr)

beetlemania <- beetle_df %>%
  add_residuals(beetle_lm)

head(beetlemania)

```



```{r}

qplot(wingMass, resid, data=beetlemania) +
  stat_smooth(method = lm)

```


#### 4c. Use the graph provided and your residual plot to evaluate the main assumptions of linear regression.

<span style="color: green;">I'll add a smooth line analyze the linearity of the hornSize ~ bodymass relationship

```{r}
ggplot(data = beetle_df,
       mapping = aes(x = wingMass, y = hornSize)) +
  geom_point(colour = "yellow", size =2, shape = 1)+
  stat_smooth(fill="pink", colour="blue", size=1)+
  theme_dark()


```

<span style="color: green;">This demonstrates that the data has non-linear relationship. The residual plot also has some datapoints that infer non-normality and unequal variance.</span>



#### 4d. In light of your conclusions in part C, what steps should be taken?
<span style="color: green;">The data here forms a relationship, however, it is not the strongest. This model can be validated by increasing the sample size to reduce the deviation of horn size. Measurement methods may also be a factor in the non-linearity."

#### 4e. Do any other diagnostics misbehave?

```{r}
plot(beetle_lm, which = 1)

```

<span style="color: green;">The residuals vs. fitted plot is not a nice cloud shape</span>

####6. W&S Chapter 17-30
https://whitlockschluter.zoology.ubc.ca/wp-content/data/chapter17/chap17q30NuclearTeeth.csv 

```{r}
# load data from the web this time!

nuclear_teeth <- read.csv("https://whitlockschluter.zoology.ubc.ca/wp-content/data/chapter17/chap17q30NuclearTeeth.csv ")

str(nuclear_teeth)


```

```{r}

skimr::skim(nuclear_teeth)

```



#### Calculating the year of birth of cadavers is a tricky enterprise. One method proposed is based on the radioactivity of the enamel of the body's teeth. The proportion of the radioisotope <sup>14</sup>C in the atmosphere increased dramatically during the era of above ground nuclear bomb testing between 1955 and 1963. Given that the enamel of a tooth is a non-regenerating , measuring the <sup>14</sup>C content of a tooth tells when the tooth developed, and therefore the year of birth of its owner. Predictions based on this method seem quite accurate, as shown in the accompanying graph. he x-axis  A<sup>14</sup>C, which measures the amount of <sup>14</sup>C relative to a standard (as a percentage).

####There are three sets of lines on this graph. The solid line represent the least-squares regression line, prediciting the actual year of birth from the estimate based on amount of <sup>14</sup>C. One pair of dashed lines shows the 95% confidence bands and the other shows the 95% prediction interval.


```{r}
library(janitor)
#fit a model

teeth_lm <- lm(deltaC14 ~ dateOfBirth, data = nuclear_teeth)

summary(teeth_lm)
```

#### 6a. What is the approximate slope of the regression line?

<span style="color: green;">The slope of the regression line is -16.71.</span>

#### 6b. Which pair of lines shows the confidence bands? What do these confidence bands tell us?

```{r}
#generate upper and lower confidence interval
fit_teeth <- predict(teeth_lm, 
                     interval = "confidence") %>%
#put CI into tibble
  as_tibble() %>%
  rename(lwr_ci = lwr,
         upr_ci = upr)
#bind columns with df
nuclear_teeth <- cbind(nuclear_teeth, fit_teeth)



#create a plot
ggplot(nuclear_teeth,
       aes(x = dateOfBirth, 
           ymin = lwr_ci, 
           ymax = upr_ci,
           y = fit)) +
  geom_ribbon(fill = "orange") +
  geom_line(color = "blue")+
  theme_dark()
```


<span style="color: green;">The confidence interval is shown in orange. These lines show the predicted mean-Y for a given X and a re useful for predicting the general trend of a linear model. These bands will bracket the regression line for 95% of the samples.</span>

#### 6c. What pair of lines show the prediction interval? What do these confidence interval bands tell us?

#### 6d. Using predict() and geom_ribbon() in ggplot2, reproduce the above plot showing data, fit, fit interval, and prediction interval.


```{r}
# Predicition Interval
predict_teeth <- predict(teeth_lm,
                         interval = "prediction") %>%
  as_tibble() %>%
  rename(lwr_pi = lwr,
         upr_pi = upr)

nuclear_teeth <- cbind(nuclear_teeth, predict_teeth) 
# fix the names 

nuclear_teeth <- janitor::clean_names(nuclear_teeth)



ggplot(data = nuclear_teeth,
       mapping = aes(x = date_of_birth,
                     y = delta_c14)) +
  geom_point(fill = "white")+
  #prediction interval
  geom_ribbon(mapping = aes(ymin = lwr_pi,
                            ymax = upr_pi),
              fill = "green",
              alpha = 0.5) +
  # fit interval - just coefficient error (precision)
  geom_ribbon(mapping = aes(ymin = lwr_ci,
                            ymax = upr_ci),
              fill = "orange",
              alpha = 0.5)+
  stat_smooth(method=lm)+
  theme_dark()
```

<span style="color: green;">The green band represents the prediction interval which represents the upper and lower limits for a single-Y over any given X. These are wider than confidence intervals because they account for the variability in the dependent variable across all values of a independent variable.</span>

